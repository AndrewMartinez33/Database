"""
Fuzzy DataFrame Search CLI Tool
A high-performance fuzzy search tool for tabular data files.
"""

__version__ = "1.2.0"

import sys
from pathlib import Path
from typing import List, Optional, Tuple, Dict, Any
import re
import click
from rapidfuzz import fuzz, process
from rich.console import Console
from rich.table import Table
from rich.text import Text
from rich.panel import Panel
from rich import box
from rich.prompt import Prompt

try:
    import polars as pl
    USE_POLARS = True
except ImportError:
    console.print("[red]Error: Polars is required for this tool[/red]")
    console.print("[yellow]Install with: pip install polars pyarrow openpyxl[/yellow]")
    sys.exit(1)

try:
    import pyarrow
    HAS_PYARROW = True
except ImportError:
    console.print("[yellow]âš  PyArrow not found - some features may not work. Install with: pip install pyarrow[/yellow]")
    HAS_PYARROW = False

console = Console()


def auto_detect_file() -> str:
    """Auto-detect a data file in the current directory."""
    extensions = ['.csv', '.json', '.xlsx', '.xls', '.parquet']
    current_dir = Path('.')
    
    data_files = []
    for ext in extensions:
        data_files.extend(list(current_dir.glob(f'*{ext}')))
    
    # Sort for consistent ordering
    data_files = sorted(data_files, key=lambda x: x.name.lower())
    
    if not data_files:
        console.print("[red]Error: No data files found in current directory[/red]")
        console.print("[yellow]Supported formats: CSV, JSON, Excel (.xlsx/.xls), Parquet[/yellow]")
        console.print("[dim]Hint: Use --file to specify a file path[/dim]")
        sys.exit(1)
    
    if len(data_files) == 1:
        console.print(f"[dim]Auto-detected: {data_files[0].name}[/dim]")
        return str(data_files[0])
    
    # Multiple files found - show menu
    console.print("[yellow]Multiple data files found:[/yellow]")
    for i, f in enumerate(data_files, 1):
        file_size = f.stat().st_size / 1024  # KB
        size_str = f"{file_size:.1f}KB" if file_size < 1024 else f"{file_size/1024:.1f}MB"
        console.print(f"  {i}. {f.name} ({size_str})")
    
    try:
        choice = click.prompt("Select file number", type=int, default=1)
        if 1 <= choice <= len(data_files):
            return str(data_files[choice - 1])
        else:
            console.print("[red]Invalid selection[/red]")
            sys.exit(1)
    except (KeyboardInterrupt, EOFError):
        console.print("\n[yellow]Cancelled[/yellow]")
        sys.exit(0)
    except click.Abort:
        console.print("\n[yellow]Cancelled[/yellow]")
        sys.exit(0)


def load_dataframe(file_path: str) -> pl.DataFrame:
    """Load dataframe from various file formats using Polars."""
    path = Path(file_path)
    
    if not path.exists():
        console.print(f"[red]Error: File '{file_path}' not found[/red]")
        sys.exit(1)
    
    suffix = path.suffix.lower()
    
    try:
        if suffix == '.csv':
            df = pl.read_csv(file_path, ignore_errors=True)
        elif suffix == '.json':
            df = pl.read_json(file_path)
        elif suffix in ['.xlsx', '.xls']:
            if not HAS_PYARROW:
                console.print("[red]Error: PyArrow is required for Excel files[/red]")
                console.print("[yellow]Install with: pip install pyarrow openpyxl[/yellow]")
                sys.exit(1)
            df = pl.read_excel(file_path)
        elif suffix == '.parquet':
            df = pl.read_parquet(file_path)
        else:
            console.print(f"[red]Unsupported file format: {suffix}[/red]")
            console.print("[yellow]Supported: .csv, .json, .xlsx, .xls, .parquet[/yellow]")
            sys.exit(1)
        
        return df
    except FileNotFoundError:
        console.print(f"[red]Error: File '{file_path}' not found[/red]")
        sys.exit(1)
    except PermissionError:
        console.print(f"[red]Error: Permission denied accessing '{file_path}'[/red]")
        sys.exit(1)
    except Exception as e:
        console.print(f"[red]Error loading file: {e}[/red]")
        console.print(f"[dim]File: {file_path}[/dim]")
        sys.exit(1)


def validate_columns(df: pl.DataFrame, columns: List[str]) -> List[str]:
    """Validate that specified columns exist in dataframe."""
    available_cols = list(df.columns)
    invalid_cols = [col for col in columns if col not in available_cols]
    
    if invalid_cols:
        console.print(f"[red]Error: Column(s) not found: {', '.join(invalid_cols)}[/red]")
        console.print(f"[yellow]Available columns:[/yellow]")
        for col in available_cols[:10]:  # Show first 10
            console.print(f"  â€¢ {col}")
        if len(available_cols) > 10:
            console.print(f"  ... and {len(available_cols) - 10} more")
        sys.exit(1)
    
    return columns


def search_nulls_blanks(
    df: pl.DataFrame,
    columns: Optional[List[str]] = None,
    search_type: str = "null"  # "null" or "blank"
) -> pl.DataFrame:
    """Search for null or blank values in specified columns."""
    search_columns = columns if columns else list(df.columns)
    
    if columns:
        search_columns = validate_columns(df, columns)
    
    # Build filter condition
    conditions = []
    for col in search_columns:
        if search_type == "null":
            conditions.append(pl.col(col).is_null())
        elif search_type == "blank":
            # Check for null OR empty string OR whitespace-only
            conditions.append(
                pl.col(col).is_null() | 
                (pl.col(col).cast(pl.Utf8).str.strip_chars() == "")
            )
    
    # Combine conditions with OR
    if conditions:
        filter_condition = conditions[0]
        for cond in conditions[1:]:
            filter_condition = filter_condition | cond
        
        return df.filter(filter_condition)
    
    return df.head(0)  # Return empty dataframe


def regex_search_dataframe(
    df: pl.DataFrame,
    pattern: str,
    columns: Optional[List[str]] = None,
    case_sensitive: bool = False,
    limit: int = 20
) -> List[Tuple[int, int, str, str]]:
    """
    Perform regex search across dataframe columns.
    Returns list of (row_index, score, matching_column, match_text) tuples.
    Score is always 100 for regex matches (either matches or doesn't).
    """
    if columns:
        search_columns = columns
    else:
        search_columns = list(df.columns)
    
    # Validate columns exist
    if columns:
        search_columns = validate_columns(df, columns)
    
    # Compile regex pattern
    try:
        flags = 0 if case_sensitive else re.IGNORECASE
        regex = re.compile(pattern, flags)
    except re.error as e:
        console.print(f"[red]Invalid regex pattern: {e}[/red]")
        sys.exit(1)
    
    results = []
    
    for col in search_columns:
        try:
            # Convert column to string list
            col_data = df[col].fill_null("").cast(pl.Utf8).to_list()
            
            # Skip empty columns
            if not any(col_data):
                continue
            
            # Search for regex matches
            for idx, value in enumerate(col_data):
                if regex.search(str(value)):
                    results.append((idx, 100, col, str(value)))
                    
                    # Stop if we've hit the limit
                    if len(results) >= limit:
                        return results
        
        except Exception as e:
            console.print(f"[yellow]Warning: Could not search column '{col}': {e}[/yellow]")
            continue
    
    return results[:limit]


def fuzzy_search_dataframe(
    df: pl.DataFrame,
    query: str,
    columns: Optional[List[str]] = None,
    threshold: int = 70,
    limit: int = 20,
    case_sensitive: bool = False
) -> List[Tuple[int, int, str, str]]:
    """
    Perform fuzzy search across dataframe columns.
    Returns list of (row_index, score, matching_column, match_text) tuples.
    """
    if columns:
        search_columns = columns
    else:
        search_columns = list(df.columns)
    
    # Validate columns exist
    if columns:
        search_columns = validate_columns(df, columns)
    
    results = []
    
    for col in search_columns:
        try:
            # Convert column to string list, handling various data types
            col_data = df[col].fill_null("").cast(pl.Utf8).to_list()
            
            # Skip empty columns
            if not any(col_data):
                continue
            
            # For case-insensitive search, convert both query and data to lowercase
            if case_sensitive:
                search_query = query
                search_data = col_data
            else:
                search_query = query.lower()
                search_data = [s.lower() for s in col_data]
            
            # Perform fuzzy matching
            matches = process.extract(
                search_query,
                search_data,
                scorer=fuzz.WRatio,
                limit=None,
                score_cutoff=threshold
            )
            
            for match_text, score, idx in matches:
                # Return the original text, not the lowercased version
                original_text = col_data[idx]
                results.append((idx, score, col, original_text))
        
        except Exception as e:
            console.print(f"[yellow]Warning: Could not search column '{col}': {e}[/yellow]")
            continue
    
    # Sort by score (descending) and take top results
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:limit]


def highlight_match(text: str, query: str, is_regex: bool = False, case_sensitive: bool = False) -> Text:
    """Highlight matching portions of text."""
    text_str = str(text)
    
    if is_regex:
        # For regex, highlight all matches
        rich_text = Text()
        try:
            flags = 0 if case_sensitive else re.IGNORECASE
            pattern = re.compile(query, flags)
            last_end = 0
            
            for match in pattern.finditer(text_str):
                start, end = match.span()
                # Add text before match
                rich_text.append(text_str[last_end:start])
                # Add highlighted match
                rich_text.append(text_str[start:end], style="bold yellow on blue")
                last_end = end
            
            # Add remaining text
            rich_text.append(text_str[last_end:])
            
            # If no matches were highlighted, just return the text
            if last_end == 0:
                return Text(text_str, style="cyan")
            
            return rich_text
        except:
            return Text(text_str, style="cyan")
    else:
        # Original fuzzy highlighting logic
        text_lower = text_str.lower()
        query_lower = query.lower()
        
        rich_text = Text()
        
        if query_lower in text_lower:
            start = text_lower.index(query_lower)
            end = start + len(query)
            
            rich_text.append(text_str[:start])
            rich_text.append(text_str[start:end], style="bold yellow on blue")
            rich_text.append(text_str[end:])
        else:
            rich_text.append(text_str, style="cyan")
        
        return rich_text


def paginate_results(
    df: pl.DataFrame,
    results: List[Tuple[int, int, str, str]],
    query: str,
    show_columns: Optional[List[str]] = None,
    page_size: int = 20,
    is_regex: bool = False,
    case_sensitive: bool = False
):
    """Display results with pagination support."""
    
    if not results:
        console.print(Panel(
            "[yellow]No matches found[/yellow]\n"
            "[dim]Try lowering the threshold with -t flag (e.g., -t 60)[/dim]",
            title="Search Results",
            border_style="yellow"
        ))
        return
    
    # Get unique results
    seen_indices = set()
    unique_results = []
    for result in results:
        idx = result[0]
        if idx not in seen_indices:
            seen_indices.add(idx)
            unique_results.append(result)
    
    total_results = len(unique_results)
    total_pages = (total_results + page_size - 1) // page_size
    current_page = 0
    
    all_columns = list(df.columns)
    if show_columns:
        display_cols = validate_columns(df, show_columns)
    else:
        display_cols = all_columns[:min(5, len(all_columns))]
    
    while True:
        # Calculate page boundaries
        start_idx = current_page * page_size
        end_idx = min(start_idx + page_size, total_results)
        page_results = unique_results[start_idx:end_idx]
        
        # Create table for current page
        table = Table(
            title=f"ðŸ” Search Results for: '{query}' (Page {current_page + 1}/{total_pages})",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold magenta",
            border_style="bright_blue",
            show_lines=False
        )
        
        table.add_column("#", style="dim", justify="right", width=4)
        table.add_column("Score", style="green", justify="right", width=6)
        table.add_column("Match Column", style="cyan", width=20, no_wrap=True)
        
        for col in display_cols:
            table.add_column(col, style="white", max_width=40, overflow="fold")
        
        # Add rows for current page
        for result_idx, (idx, score, match_col, match_text) in enumerate(page_results, start=start_idx + 1):
            try:
                row = df[idx]
                row_data = {col: str(row[col][0]) if row[col][0] is not None else "" for col in all_columns}
                
                row_values = [
                    str(result_idx),
                    f"{score}%",
                    match_col[:18] + "..." if len(match_col) > 18 else match_col
                ]
                
                for col in display_cols:
                    value = row_data.get(col, "")
                    if col == match_col:
                        row_values.append(highlight_match(value, query, is_regex, case_sensitive))
                    else:
                        truncated = value[:200] if len(value) > 200 else value
                        row_values.append(truncated)
                
                table.add_row(*row_values)
            
            except Exception as e:
                console.print(f"[dim]Warning: Could not display row {idx}: {e}[/dim]")
                continue
        
        console.clear()
        console.print(table)
        console.print(f"\n[dim]Showing results {start_idx + 1}-{end_idx} of {total_results} total matches[/dim]")
        
        if not show_columns and len(all_columns) > 5:
            console.print(f"[dim]Hint: Use --show to display specific columns (showing {len(display_cols)} of {len(all_columns)} columns)[/dim]")
        
        # Pagination controls
        if total_pages > 1:
            console.print("\n[bold cyan]Navigation:[/bold cyan] [n]ext | [p]revious | [g]oto page | [q]uit")
            choice = Prompt.ask("", default="n").lower()
            
            if choice == 'q':
                break
            elif choice == 'n':
                if current_page < total_pages - 1:
                    current_page += 1
                else:
                    console.print("[yellow]Already at last page[/yellow]")
                    continue
            elif choice == 'p':
                if current_page > 0:
                    current_page -= 1
                else:
                    console.print("[yellow]Already at first page[/yellow]")
                    continue
            elif choice == 'g':
                try:
                    page_num = int(Prompt.ask("Enter page number", default="1"))
                    if 1 <= page_num <= total_pages:
                        current_page = page_num - 1
                    else:
                        console.print(f"[yellow]Invalid page. Enter 1-{total_pages}[/yellow]")
                        continue
                except ValueError:
                    console.print("[yellow]Invalid page number[/yellow]")
                    continue
            else:
                # Treat any other input as 'next'
                if current_page < total_pages - 1:
                    current_page += 1
                else:
                    break
        else:
            break


def export_results(
    df: pl.DataFrame,
    results: List[Tuple[int, int, str, str]],
    output_path: str,
    show_columns: Optional[List[str]] = None
):
    """Export search results to a file."""
    # Get unique row indices
    seen_indices = set()
    unique_indices = []
    for idx, score, match_col, match_text in results:
        if idx not in seen_indices:
            seen_indices.add(idx)
            unique_indices.append(idx)
    
    # Filter dataframe to matching rows
    result_df = df[unique_indices]
    
    # Filter columns if specified
    if show_columns:
        show_columns = validate_columns(df, show_columns)
        result_df = result_df.select(show_columns)
    
    # Determine output format from file extension
    output_path_obj = Path(output_path)
    suffix = output_path_obj.suffix.lower()
    
    try:
        if suffix == '.csv':
            result_df.write_csv(output_path)
        elif suffix == '.json':
            result_df.write_json(output_path)
        elif suffix in ['.xlsx', '.xls']:
            if not HAS_PYARROW:
                console.print("[red]Error: PyArrow required for Excel export[/red]")
                console.print("[yellow]Install with: pip install pyarrow openpyxl[/yellow]")
                sys.exit(1)
            result_df.write_excel(output_path)
        elif suffix == '.parquet':
            result_df.write_parquet(output_path)
        else:
            console.print(f"[red]Unsupported output format: {suffix}[/red]")
            console.print("[yellow]Supported: .csv, .json, .xlsx, .parquet[/yellow]")
            sys.exit(1)
        
        console.print(f"\n[green]âœ“[/green] Exported {len(result_df)} rows to {output_path}")
    
    except Exception as e:
        console.print(f"[red]Error exporting results: {e}[/red]")
        sys.exit(1)


def display_results(
    df: pl.DataFrame,
    results: List[Tuple[int, int, str, str]],
    query: str,
    show_columns: Optional[List[str]] = None,
    is_regex: bool = False,
    case_sensitive: bool = False
):
    """Display search results in a beautiful table (non-paginated version)."""
    
    if not results:
        console.print(Panel(
            "[yellow]No matches found[/yellow]\n"
            "[dim]Try lowering the threshold with -t flag (e.g., -t 60)[/dim]",
            title="Search Results",
            border_style="yellow"
        ))
        return
    
    # Create results table
    table = Table(
        title=f"ðŸ” Search Results for: '{query}'",
        box=box.ROUNDED,
        show_header=True,
        header_style="bold magenta",
        border_style="bright_blue",
        show_lines=False
    )
    
    table.add_column("Score", style="green", justify="right", width=6)
    table.add_column("Match Column", style="cyan", width=20, no_wrap=True)
    
    # Determine which columns to display
    all_columns = list(df.columns)
    
    if show_columns:
        # Validate show columns exist
        display_cols = validate_columns(df, show_columns)
    else:
        # Default to first 5 columns or all if fewer
        display_cols = all_columns[:min(5, len(all_columns))]
    
    for col in display_cols:
        table.add_column(col, style="white", max_width=40, overflow="fold")
    
    # Add rows
    seen_indices = set()
    for idx, score, match_col, match_text in results:
        if idx in seen_indices:
            continue
        seen_indices.add(idx)
        
        try:
            # Get row data using Polars
            row = df[idx]
            row_data = {col: str(row[col][0]) if row[col][0] is not None else "" for col in all_columns}
            
            # Build table row
            row_values = [
                f"{score}%",
                match_col[:18] + "..." if len(match_col) > 18 else match_col
            ]
            
            for col in display_cols:
                value = row_data.get(col, "")
                if col == match_col:
                    row_values.append(highlight_match(value, query, is_regex, case_sensitive))
                else:
                    # Truncate long values
                    truncated = value[:200] if len(value) > 200 else value
                    row_values.append(truncated)
            
            table.add_row(*row_values)
        
        except Exception as e:
            console.print(f"[dim]Warning: Could not display row {idx}: {e}[/dim]")
            continue
    
    console.print(table)
    console.print(f"\n[dim]Showing {len(seen_indices)} unique result(s) out of {len(df)} total rows[/dim]")
    
    # Show hint if display columns are limited
    if not show_columns and len(all_columns) > 5:
        console.print(f"[dim]Hint: Use --show to display specific columns (showing {len(display_cols)} of {len(all_columns)} columns)[/dim]")


@click.command()
@click.argument('query', required=False)
@click.argument('columns', nargs=-1)
@click.option('--file', '-f', default=None, help='Data file path (auto-detected if not specified)')
@click.option('--threshold', '-t', default=70, type=click.IntRange(0, 100), help='Minimum match score (0-100)')
@click.option('--limit', '-l', default=20, type=click.IntRange(1, 10000), help='Maximum number of results')
@click.option('--show', '-s', multiple=True, help='Columns to display in results')
@click.option('--output', '-o', default=None, help='Export results to file (.csv, .json, .xlsx, .parquet)')
@click.option('--page', '-p', is_flag=True, help='Enable pagination for results')
@click.option('--page-size', default=20, type=click.IntRange(1, 100), help='Results per page (default: 20)')
@click.option('--null', 'search_null', is_flag=True, help='Search for null values in specified columns')
@click.option('--blank', 'search_blank', is_flag=True, help='Search for blank/empty values in specified columns')
@click.option('--case-sensitive', '-c', is_flag=True, help='Enable case-sensitive search (default: case-insensitive)')
@click.option('--regex', '-r', is_flag=True, help='Enable regex search mode')
@click.version_option(version=__version__)
def main(
    query: Optional[str],
    columns: tuple,
    file: Optional[str],
    threshold: int,
    limit: int,
    show: tuple,
    output: Optional[str],
    page: bool,
    page_size: int,
    search_null: bool,
    search_blank: bool,
    case_sensitive: bool,
    regex: bool
):
    """
    Fuzzy search through dataframes with beautiful terminal output.
    
    Usage: 
        fuzz "search query" [column1 column2 ...]
        fuzz "john smith" name email
        fuzz "acme" company --show name phone
        fuzz --null email phone              # Find null values
        fuzz --blank company                  # Find blank values
        fuzz "search" -o results.csv         # Export results
        fuzz "search" --page                  # Paginate results
        fuzz "John" --case-sensitive         # Case-sensitive search
        fuzz "^[A-Z]{3}$" --regex            # Regex search
        fuzz "\\d{3}-\\d{3}-\\d{4}" phone -r # Phone pattern
    
    By default, searches are case-insensitive fuzzy matching. 
    Use --case-sensitive for exact case, --regex for pattern matching.
    Auto-detects data files in current directory if --file not specified.
    Supports CSV, JSON, Excel, and Parquet files.
    """
    
    # Auto-detect file if not provided
    if file is None:
        file_path = auto_detect_file()
    else:
        file_path = file
    
    # Display header
    console.print(Panel.fit(
        "[bold blue]Fuzzy DataFrame Search[/bold blue]\n"
        f"[dim]File: {file_path}[/dim]",
        border_style="blue"
    ))
    
    # Load data
    try:
        with console.status("[bold green]Loading data..."):
            df = load_dataframe(file_path)
        
        row_count = len(df)
        col_count = len(df.columns)
        
        if row_count == 0:
            console.print("[yellow]Warning: File contains no data rows[/yellow]")
            sys.exit(1)
        
        console.print(f"[green]âœ“[/green] Loaded {row_count:,} rows, {col_count} columns")
        console.print("[dim]âœ“ Using Polars (high-performance mode)[/dim]")
    
    except KeyboardInterrupt:
        console.print("\n[yellow]Cancelled[/yellow]")
        sys.exit(0)
    
    # Handle null/blank search
    if search_null or search_blank:
        search_type = "blank" if search_blank else "null"
        search_label = "blank/empty" if search_blank else "null"
        
        search_columns = list(columns) if columns else None
        
        with console.status(f"[bold green]Searching for {search_label} values..."):
            result_df = search_nulls_blanks(df, search_columns, search_type)
        
        if len(result_df) == 0:
            console.print(f"\n[green]âœ“[/green] No {search_label} values found!")
        else:
            console.print(f"\n[yellow]Found {len(result_df)} rows with {search_label} values[/yellow]")
            
            # Display sample results
            display_cols = list(show) if show else list(df.columns)[:5]
            display_cols = validate_columns(df, display_cols) if show else display_cols
            
            table = Table(title=f"Rows with {search_label.title()} Values", box=box.ROUNDED)
            for col in display_cols:
                table.add_column(col, style="white", max_width=40, overflow="fold")
            
            # Show first 20 results
            for i in range(min(20, len(result_df))):
                row = result_df[i]
                row_values = [str(row[col][0]) if row[col][0] is not None else "[red]NULL[/red]" for col in display_cols]
                table.add_row(*row_values)
            
            console.print(table)
            
            if len(result_df) > 20:
                console.print(f"\n[dim]Showing first 20 of {len(result_df)} results[/dim]")
            
            # Export if requested
            if output:
                # Create fake results list for export function
                results = [(i, 100, "", "") for i in range(len(result_df))]
                export_results(result_df, results, output, list(show) if show else None)
        
        return
    
    # Validate query is not empty for regular search
    if not query or not query.strip():
        console.print("[red]Error: Search query cannot be empty[/red]")
        console.print("[dim]Use --null or --blank to search for missing values[/dim]")
        sys.exit(1)
    
    # Perform search (regex or fuzzy)
    search_columns = list(columns) if columns else None
    
    try:
        # Display search mode
        if regex:
            search_mode = f"regex ({'case-sensitive' if case_sensitive else 'case-insensitive'})"
        else:
            search_mode = "case-sensitive" if case_sensitive else "case-insensitive"
        console.print(f"[dim]Search mode: {search_mode}[/dim]")
        
        with console.status(f"[bold green]Searching for '{query}'..."):
            if regex:
                results = regex_search_dataframe(
                    df,
                    query,
                    columns=search_columns,
                    case_sensitive=case_sensitive,
                    limit=limit
                )
            else:
                results = fuzzy_search_dataframe(
                    df,
                    query,
                    columns=search_columns,
                    threshold=threshold,
                    limit=limit,
                    case_sensitive=case_sensitive
                )
    except KeyboardInterrupt:
        console.print("\n[yellow]Search cancelled[/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]Error during search: {e}[/red]")
        sys.exit(1)
    
    # Export results if requested
    if output:
        export_results(df, results, output, list(show) if show else None)
    
    # Display results with or without pagination
    try:
        if page:
            paginate_results(
                df,
                results,
                query,
                show_columns=list(show) if show else None,
                page_size=page_size,
                is_regex=regex,
                case_sensitive=case_sensitive
            )
        else:
            display_results(
                df,
                results,
                query,
                show_columns=list(show) if show else None,
                is_regex=regex,
                case_sensitive=case_sensitive
            )
    except KeyboardInterrupt:
        console.print("\n[yellow]Display cancelled[/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]Error displaying results: {e}[/red]")
        sys.exit(1)


if __name__ == '__main__':
    main()
